{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "parsing_bl_pandas",
      "provenance": [],
      "authorship_tag": "ABX9TyPwtbh9vUgDT7LLJX876h21",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/NIS_SentiFrame/blob/master/parsing_bl_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuYmVxZLvIUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pymorphy2[fast]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjOpLg87c_h4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "# для переноса джейсона в датафрейм\n",
        "from pandas.io.json import json_normalize\n",
        "\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "morph = MorphAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cQYM1S_rXQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! wget https://raw.githubusercontent.com/nicolay-r/RuSentiFrames/master/collection.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5mBGZ4prROq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# загружаем базовый лексикон\n",
        "with open ('collection.json') as jf:\n",
        "  bl_data = json.load(jf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rB3R6xGOQKj",
        "colab_type": "code",
        "outputId": "c5f995da-1ad3-4c79-f124-ca51797d55db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# задаём названия колонок, хотя этого можно и не делать, наверное\n",
        "cols = ['title', 'variants', 'comment', 'roles.a0', 'roles.a1', 'roles.a2', 'roles.a3',\n",
        "       'frames.polarity', 'frames.effect', 'frames.state', 'variant', 'key']\n",
        "\n",
        "# создаём шаблон итогового датафрейма с нужными колонками (см. выше)\n",
        "# к нему будем приклеивать датафреймы, в которых строки будут различаться лишь\n",
        "# колонкой вариант\n",
        "bl_df = pd.DataFrame(columns=cols)\n",
        "\n",
        "# для каждого фрейма\n",
        "for fr in bl_data:\n",
        "  # достаём фрейм\n",
        "  frame = bl_data[fr]\n",
        "  # создаём второй шаблон, к которому будем приклеивать строки для каждого варианта\n",
        "  # когда наполним этот второй шаблон, он отправится в итоговый дф\n",
        "  df = pd.DataFrame(columns=cols)\n",
        "\n",
        "\n",
        "  # для каждого варианта предиката\n",
        "  for variant in frame['variants']:\n",
        "    # переносим джейсон фрейма, с которым работаем, в датафрейм из одной строки\n",
        "    # max_level=1 потому что дальше фрейм не разворачивается\n",
        "    base_df = json_normalize(frame, max_level=1)\n",
        "    # в новую колонку кладём вариант\n",
        "    base_df['variant'] = [variant]\n",
        "    # ко второму дф приклеиваем дф-строку с вариантом, индекс сбрасываем\n",
        "    # не сортируем, чтоб нимношк быстрее было\n",
        "    df = df.append(base_df, ignore_index=True, sort=False)\n",
        "\n",
        "\n",
        "  # на этом этапе у нас df для фрейма наполнился одинаковыми строками\n",
        "  # где только варианты различаются\n",
        "  # ключ, соответствующий фрейму, лежит в fr\n",
        "  # до кучи положим его туда же, в каждую строку\n",
        "  df['key'] = [fr for i in range(0,len(frame['variants']))]\n",
        "  # получившийся дф для фрейма приклеиваем к итоговому\n",
        "  bl_df = bl_df.append(df, ignore_index=True, sort=False)\n",
        "  # идём в следующий фрейм\n",
        "\n",
        "# смотрим, сколько строчек вышло в дф и не потеряли ли мы что-то\n",
        "len(bl_df)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6247"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6Z6YkqDMdWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# дропнем лишние колонки\n",
        "# хотя можно и не дропать\n",
        "# две колонки комментариев хорошо бы было совместить конечно и оставить\n",
        "bl_df.drop(['comment', 'comments', 'frames.value', 'title', 'variants'], axis=1, inplace=True)\n",
        "\n",
        "# вот такие колонки остались на этом этапе\n",
        "# bl_df.columns\n",
        "# ['roles.a0', 'roles.a1', 'roles.a2', 'roles.a3', 'frames.polarity', 'frames.effect', 'frames.state', 'variant', 'key']\n",
        "# многие ячейки заполнены NaN-ами"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVlU5aXagHOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # это всё неважно, поэтому закаменчено\n",
        "\n",
        "# # посмотрим, какие эттитьюдс бывают вообще в базовом лексиконе\n",
        "# pol_counter = Counter()\n",
        "# # для листа полярностей из каждой строчки дф (этот лист хранится в колонке frames.polarity)\n",
        "# for pol_lst in bl_df[\n",
        "#                      # (смотрим только на те строки, где полярити вообще есть)\n",
        "#                      bl_df['frames.polarity'].notnull()\n",
        "#                      ]['frames.polarity'].values:\n",
        "#   # для отдельной полярности в этом листе (которая как тип тоже лист)\n",
        "#   for pol in pol_lst:\n",
        "#     # кладём двух склеенных через пробел участников как строку в каунтер\n",
        "#     pol_counter.update([' '.join([str(el) for el in pol])])\n",
        "# # смотрим, что вышло\n",
        "# pol_counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKYeXIERxOc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # это тоже неважно\n",
        "# #  но прикольно, что в каком-то фрейме аж 11 полярностей\n",
        "\n",
        "# # добавим колонку с количеством полярностей\n",
        "# bl_df['n_polarities'] = bl_df['frames.polarity'].apply(lambda x: len(x) if type(x)==list else 0)\n",
        "# # посмотрим на то, сколько полярностей может быть во фрейме\n",
        "# Counter(bl_df['n_polarities'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PYsEbiMcYHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # а в этих фреймах вообще нет эффекта\n",
        "# set(bl_df[bl_df['frames.effect'].isnull()]['key'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY6lJCIjnEkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # а это какие бывают эффекты\n",
        "\n",
        "# effect_counter = Counter()\n",
        "# for effect_lst in bl_df[bl_df['frames.effect'].notnull()]['frames.effect'].values:\n",
        "#   for effect in effect_lst:\n",
        "#     effect_counter.update([' '.join([str(el) for el in effect])])\n",
        "# effect_counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYAWlV73lehX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # можно запринтить все возможные пары отношений\n",
        "# но это не особо интересно\n",
        "\n",
        "# possible_attitudes_set = set(['_'.join(pol.split()[0:2]) for pol in pol_counter])\n",
        "# for attitude in possible_attitudes_set:\n",
        "#   print (attitude)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYv4wSF69DIE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "d1cc0eed-8051-4d45-aa98-84ba20bc08dc"
      },
      "source": [
        "# посмотрим, сколько всего повторяющихся вариантов предикатов\n",
        "# их 196\n",
        "\n",
        "bl_df.variant.value_counts().head(197)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "прослеживать        3\n",
              "обставлять          3\n",
              "снижение            3\n",
              "проследить          3\n",
              "колоть              3\n",
              "                   ..\n",
              "углубить            2\n",
              "замарать            2\n",
              "расстроиться        2\n",
              "следовать           2\n",
              "применить оружие    1\n",
              "Name: variant, Length: 197, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meYG12KpkkMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ну, терь самое главное (типа)\n",
        "\n",
        "# идем по строкам\n",
        "for row in bl_df.itertuples():\n",
        "  # достаём индес строки\n",
        "  row_id = row[0]\n",
        "  # и достаём из неё лист полярностей\n",
        "  polarities_list = row[5]\n",
        "\n",
        "  # пытаемся\n",
        "  try:\n",
        "    # для отдельной полярности\n",
        "    for polarity in polarities_list:\n",
        "\n",
        "      # обращаемся к элементам полярности (которая сама список) по индексу\n",
        "      # элемент с индексом 0 - это тот, кто относится\n",
        "      # элемент  индексом 1 - тот, к кому относятся\n",
        "      # создаём название колонки формата 'КтоОтносится_ККому'\n",
        "      col = '{}_{}'.format(polarity[0], polarity[1])\n",
        "\n",
        "      #  обращаемся к ячейке по адресу [индекс строки, название новой колонки]\n",
        "      # заполняем эту ячейку меткой (метка - это элемент полярности с индексом 2)\n",
        "      # ну, метка бывает pos или neg\n",
        "      # степень уверенности не берём с собой\n",
        "      bl_df.loc[row_id, col] = polarity[2]\n",
        "\n",
        "\n",
        "      # чтоб сохранить меру уверенности, можно её приклеить к метке,\n",
        "      # если заменить строку выше на строку ниже\n",
        "      # но в данный момент неясно, зачем она нужна, так что не будем\n",
        "      # bl_df.loc[row_id, col] = '{} {}'.format(polarity[2], polarity[3])\n",
        "  \n",
        "  # если попытка не удалась, значит в полярности NaN\n",
        "  except:\n",
        "    pass\n",
        "  # идём в следующую строку"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF4-0R1PDZoR",
        "colab_type": "text"
      },
      "source": [
        "#Достаём списком"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EzNV8g2Ku0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# тут по условию достаётся список глаголов\n",
        "# раскаментим одно из двух условий ниже\n",
        "\n",
        "condition = 'pos'\n",
        "# condition = 'neg'\n",
        "\n",
        "# по условиям достаём варианты\n",
        "variants = bl_df[\n",
        "      \n",
        "      # первое условие\n",
        "      (bl_df.a0_a1 == condition)\n",
        "      \n",
        "      # логическое И\n",
        "      &\n",
        "      \n",
        "      # второе условие\n",
        "      (bl_df.a1_a0 == condition)\n",
        "\n",
        "      # можно добавить ещё миллион каких-нить условий вот в таком формате\n",
        "      # &\n",
        "      # (bl_df.a1_a0 == condition)\n",
        "\n",
        "]['variant'].values\n",
        "\n",
        "# нам интересны только те предикаты, которым пайморфи даёт pos-тег инфинитива\n",
        "# или финитного глагола (на всякий)\n",
        "# ну и чтобы предикат был одним словом, никаких пробелов\n",
        "candidates = [variant for variant in variants \n",
        "              if \n",
        "              (' ' not in variant) \n",
        "              and \n",
        "              (('INFN' or 'VERB') in morph.parse(variant)[0].tag)\n",
        "              ]\n",
        "# имя файла будет с интересующей нас меткой в начале\n",
        "fname = \"{}_candidates_list.json\".format(condition)\n",
        "\n",
        "# сбрасываем лист кандидатов туда\n",
        "with open(fname, \"w\") as write_file:\n",
        "    json.dump(candidates, write_file, \n",
        "              # это чтоб нормально кириллица записалась\n",
        "              ensure_ascii=False\n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g3u_Hcjf4Hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# делаем допущение, что так у нас получится вытащить глаголы с аргументом в дативе\n",
        "# и второе допущение - что такие аргументы лежат в а1\n",
        "# на самом деле мы поэкспериментировали с а0 и а2 и a3 тоже\n",
        "# эксперименты показали, что лучше их в a1 искать\n",
        "\n",
        "# заводим новую колонку 'to_whom'\n",
        "# в ней будем хранить тру и фолс\n",
        "# тру - мб датив есть\n",
        "# фолс - мб его нету\n",
        "\n",
        "# смотрим на описание роли a1\n",
        "# если в нём есть ', кому' ИЛИ ', чему', лямбда-функция возвращает True\n",
        "# и кладёт его в новую колонку\n",
        "# ну и кладёт фолс если нету ни одной из этих строк в описании\n",
        "# такого аргумента может и не быть, поэтому на всякий конвертируем его в строку\n",
        "# эксепшены я не умею делать! научите...\n",
        "bl_df['to_whom'] = bl_df['roles.a1'].apply(lambda x: (', кому' or ', чему') in str(x))\n",
        "\n",
        "# в список кандидатов на датив кладём только нужные\n",
        "# отсеиваем нужные по условиям\n",
        "dative_candidates = [variant for variant\n",
        "                    # во-первых, чтобы тру лежало в 'to_whom'\n",
        "                     in bl_df[bl_df['to_whom'] == True]['variant'].values \n",
        "                    # во-вторых, чтоб это был глагол\n",
        "                     if (' ' not in variant) and (('INFN' or 'VERB') in morph.parse(variant)[0].tag)]\n",
        "\n",
        "# сбрасываем получившийся список в файл\n",
        "with open(\"dative_candidates_list.json\", \"w\") as write_file:\n",
        "    json.dump(dative_candidates, write_file, ensure_ascii=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAUkWwzfDhcL",
        "colab_type": "text"
      },
      "source": [
        "#Достаём словарём"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jrvzs3tsk8kg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# таким же образом достаём словарь вида {'глагол':'список полярностей'}\n",
        "# если попадаются дубликаты, записывается полярность последнего\n",
        "\n",
        "condition = 'pos'\n",
        "# condition = 'neg'\n",
        "\n",
        "conditioned_df = bl_df[\n",
        "      (bl_df.a0_a1 == condition)\n",
        "      &\n",
        "      (bl_df.a1_a0 == condition)\n",
        "      # можно добавить ещё миллион каких-нить условий вот в таком формате\n",
        "      # &\n",
        "      # (bl_df.a1_a0 == condition)\n",
        "]\n",
        "\n",
        "variants = conditioned_df['variant'].values\n",
        "pols = conditioned_df['frames.polarity'].values\n",
        "\n",
        "candidates = {k:v for (k,v) in dict(zip(variants, pols)).items() \n",
        "              if (' ' not in k)\n",
        "              and (('INFN' or 'VERB') in morph.parse(k)[0].tag)\n",
        "              }\n",
        "\n",
        "fname = \"{}_candidates_dict.json\".format(condition)\n",
        "\n",
        "with open(fname, \"w\") as write_file:\n",
        "    json.dump(candidates, write_file, ensure_ascii=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d5Nle7gCSGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dictionary of dative candidates\n",
        "\n",
        "bl_df['to_whom'] = bl_df['roles.a1'].apply(lambda x: (', кому' or ', чему') in str(x))\n",
        "\n",
        "conditioned_df = bl_df[bl_df['to_whom'] == True]\n",
        "\n",
        "variants = conditioned_df['variant'].values\n",
        "pols = conditioned_df['frames.polarity'].values\n",
        "\n",
        "candidates = {k:v for (k,v) in dict(zip(variants, pols)).items() \n",
        "              if (' ' not in k)\n",
        "              and (('INFN' or 'VERB') in morph.parse(k)[0].tag)\n",
        "              }\n",
        "\n",
        "# сбрасываем получившийся список в файл\n",
        "with open(\"dative_candidates_dict.json\", \"w\") as write_file:\n",
        "    json.dump(candidates, write_file, ensure_ascii=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eYEOqTKD2Aw",
        "colab_type": "text"
      },
      "source": [
        "# Пикл"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNcHlPZnaS8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # в пикл записываем подопытный датафрейм\n",
        "# # и скачиваем\n",
        "# # чтоб потом его просто загрузить\n",
        "# # но это не обязательно\n",
        "# bl_df.to_pickle('bl_df.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}