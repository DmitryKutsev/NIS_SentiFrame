{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled24.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPaNYj7ALxhZmYC9+vk5YSa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/NIS_SentiFrame/blob/master/verbs_cosine_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnAbfQ2EytKo",
        "colab_type": "code",
        "outputId": "50a23de6-901b-45c3-e6dc-066471e9f18f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget rusvectores.org/static/models/rusvectores2/news_mystem_skipgram_1000_20_2015.bin.gz\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-19 09:47:27--  http://rusvectores.org/static/models/rusvectores2/news_mystem_skipgram_1000_20_2015.bin.gz\n",
            "Resolving rusvectores.org (rusvectores.org)... 116.203.104.23\n",
            "Connecting to rusvectores.org (rusvectores.org)|116.203.104.23|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 549952184 (524M) [application/x-gzip]\n",
            "Saving to: ‘news_mystem_skipgram_1000_20_2015.bin.gz’\n",
            "\n",
            "news_mystem_skipgra 100%[===================>] 524.47M  27.5MB/s    in 20s     \n",
            "\n",
            "2020-02-19 09:47:47 (26.1 MB/s) - ‘news_mystem_skipgram_1000_20_2015.bin.gz’ saved [549952184/549952184]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LCu8A0aAaMR",
        "colab_type": "code",
        "outputId": "8186f767-6d3a-4dbc-a89f-ed4724bf028f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!rm collection.json.1 collection.json\n",
        "!wget https://raw.githubusercontent.com/nicolay-r/RuSentiFrames/master/collection.json"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'collection.json.1': No such file or directory\n",
            "rm: cannot remove 'collection.json': No such file or directory\n",
            "--2020-02-19 09:47:50--  https://raw.githubusercontent.com/nicolay-r/RuSentiFrames/master/collection.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 606414 (592K) [text/plain]\n",
            "Saving to: ‘collection.json’\n",
            "\n",
            "collection.json     100%[===================>] 592.20K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2020-02-19 09:47:50 (8.96 MB/s) - ‘collection.json’ saved [606414/606414]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvF5IwNoO638",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "from collections import Counter\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVqZukM10GFD",
        "colab_type": "code",
        "outputId": "b08eee13-99e6-4023-a0b0-ca356b41639d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "rv_model = gensim.models.KeyedVectors.load_word2vec_format('news_mystem_skipgram_1000_20_2015.bin.gz', binary=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJGCmbd6BZj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rv_model.vocab\n",
        "# rv_model.get_vector('помочь_V')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaD60ME3BB6D",
        "colab_type": "code",
        "outputId": "2d292dba-d2f4-4dbf-eee7-1762e92961c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "\n",
        "verbs_for_check_dict = {'снимать': [['a0', 'a1', 'neg', 1.0]]}\n",
        "\n",
        "def just_words_similarity(base_verb, verbs_for_check_dict):\n",
        "  \"\"\"\n",
        "  Функция тестовая, проверяет, как работает косинусная близость.\n",
        "  \"\"\"\n",
        "  group_dict = Counter()\n",
        "  my_base_verb = base_verb + '_V'\n",
        "  for verb in verbs_for_check_dict.keys():\n",
        "    verb_for_check = verb + '_V'\n",
        "    similarity = rv_model.similarity(my_base_verb, verb_for_check)\n",
        "    group_dict[str(verbs_for_check_dict[verb])] = [base_verb, verb, similarity]\n",
        "  return group_dict\n",
        "\n",
        "just_words_similarity('радоваться', verbs_for_check_dict)\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({\"[['a0', 'a1', 'neg', 1.0]]\": ['радоваться', 'снимать', 0.15058792]})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQUwjpBJjdZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rv_model.vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H52b-hi-EFHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "collection_handler = open(\"collection.json\", \"r\", encoding=\"utf-8\")\n",
        "collection = json.load(collection_handler, encoding=\"utf-8\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hCoLzvMJ_YZ",
        "colab_type": "code",
        "outputId": "f0b653f3-efcc-44b2-d50d-9323eb5e4a3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "\n",
        "def make_group(polarity_type_list):\n",
        "  \"\"\"\n",
        "  На вход подаются пары из разных типов отношений(p_type) в списках(как в переменной pol_type_dict)\n",
        "  для каждой пары цикл ищет не более ста глаголов, у которых есть типы отношений, совпадающие с нашей парой, \n",
        "  которая подается на вход. \n",
        "  \"\"\"\n",
        "  group_dict = Counter()\n",
        "  for p_type in polarity_type_list:\n",
        "    print(p_type)\n",
        "    count = 0\n",
        "    for key in collection.keys():\n",
        "      if count < 100:\n",
        "        try:\n",
        "          #print(collection[key]['frames']['polarity'])\n",
        "          if p_type[0] in collection[key]['frames']['polarity'] and p_type[1] in collection[key]['frames']['polarity'] :\n",
        "          # эту строчку можно менять, если нам нужно искать отношения, где только ['a0', 'a1', 'pos', 1.0]:\n",
        "          # if p_type[0] in collection[key]['frames']['polarity'] and p_type[1] not in collection[key]['frames']['polarity'] : \n",
        "          # проблема! в лексиконе всего 20 отношений [['a0', 'a1', 'pos', 1.0], ['a1', 'a0', 'pos', 1.0]] c разными коэффициентами, и 51 таких, \n",
        "          # где ['a0', 'a1', 'pos', 1.0], а ['a1', 'a0', 'pos', 1.0] отсутствует\n",
        "            for ver in collection[key]['title']:\n",
        "              group_dict[ver] = p_type\n",
        "              count += 1\n",
        "            for var in collection[key]['variants']:\n",
        "              if len(var.split(' ')) > 1 and var[-2:] == 'ть':\n",
        "                group_dict[var] = p_type\n",
        "                count += 1\n",
        "\n",
        "              \n",
        "        except Exception as e:\n",
        "          pass\n",
        "  return group_dict\n",
        "\n",
        "pol_type_dict = [[['a0', 'a1', 'pos', 1.0], ['a1', 'a0', 'pos', 1.0]], \\\n",
        "                 [['a0', 'a1', 'pos', 0.7], ['a1', 'a0', 'pos', 0.7]], \\\n",
        "                  [['a0', 'a1', 'neg', 0.7], ['a1', 'a0', 'neg', 0.7]], \\\n",
        "                  [['a0', 'a1', 'neg', 1.0], ['a1', 'a0', 'neg', 1.0]],\n",
        "                 ]\n",
        "\n",
        "groups_total_dict = make_group(pol_type_dict)\n",
        "len(groups_total_dict)\n",
        "# make_group(pol_type_dict)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['a0', 'a1', 'pos', 1.0], ['a1', 'a0', 'pos', 1.0]]\n",
            "[['a0', 'a1', 'pos', 0.7], ['a1', 'a0', 'pos', 0.7]]\n",
            "[['a0', 'a1', 'neg', 0.7], ['a1', 'a0', 'neg', 0.7]]\n",
            "[['a0', 'a1', 'neg', 1.0], ['a1', 'a0', 'neg', 1.0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "169"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i7pSMpM2LOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opinion_dict = ['одобрять_V', 'хвалить_V', 'поощрять_V']\n",
        "def make_sid_embedding(seed_dict, model):\n",
        "  summ = 0\n",
        "  try:\n",
        "    for verb in seed_dict:\n",
        "      #print(model[verb])\n",
        "      summ = summ + model[verb]\n",
        "  except KeyError:\n",
        "    pass\n",
        "  vector = summ/len(seed_dict)\n",
        "  return vector\n",
        "opinion_embedding = make_sid_embedding(opinion_dict, rv_model)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqNL85nDJcBx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "23f62cbc-4d91-4611-868f-553add4326d7"
      },
      "source": [
        "def get_embedding(verbs_list, model, dim=50):\n",
        "    \n",
        "    # чтобы не доставать одно слово несколько раз\n",
        "    # сделаем счетчик, а потом векторы домножим на частоту\n",
        "    words = Counter(verbs_list)\n",
        "    total = len(verbs_list)\n",
        "    vectors = np.zeros((len(words), dim))\n",
        "    \n",
        "    for i,word in enumerate(words):\n",
        "        try:\n",
        "            v = model[word]\n",
        "            vectors[i] = v*(words[word]/total) # просто умножаем вектор на частоту\n",
        "            print(vectors)\n",
        "        except (KeyError, ValueError):\n",
        "            continue\n",
        "    \n",
        "    if vectors.any():\n",
        "        vector = np.average(vectors, axis=0)\n",
        "    else:\n",
        "        vector = np.zeros((dim))\n",
        "    return vector\n",
        "\n",
        "opinion_embedding = get_embedding(opinion_dict, rv_model)\n",
        "opinion_embedding"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmVKfa8wKBKS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "e09e9049-92aa-4361-bfaa-be5c21c30ac1"
      },
      "source": [
        "opinion_dict = ['одобрять_V', 'хвалить_V', 'поощрять_V']\n",
        "def make_sid_embedding(seed_dict, model):\n",
        "  summ = 0\n",
        "  try:\n",
        "    for verb in seed_dict:\n",
        "      #print(model[verb])\n",
        "      summ = summ + get_embedding(verb, model)\n",
        "      print(summ)\n",
        "  except KeyError:\n",
        "    pass\n",
        "  vector = summ/len(seed_dict)\n",
        "  return vector\n",
        "opinion_embedding = make_sid_embedding(opinion_dict, rv_model)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Oa2r04QbrBB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8199bf94-2e7f-4ae9-c7ab-a9fe520d0aed"
      },
      "source": [
        "opinion_embedding"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2m9fHP5CnTu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "bc5c9733-e7eb-4dd6-c450-a9a373c5314b"
      },
      "source": [
        "cosine_distances(opinion_embedding, get_embedding(['хвалить_V'], rv_model, dim=50))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-1dd28c3a7f08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcosine_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopinion_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'хвалить_V'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrv_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_distances\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m    819\u001b[0m     \"\"\"\n\u001b[1;32m    820\u001b[0m     \u001b[0;31m# 1.0 - cosine_similarity(X, Y) without copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    139\u001b[0m         X = check_array(X, accept_sparse=accept_sparse, dtype=dtype,\n\u001b[1;32m    140\u001b[0m                         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                         estimator=estimator)\n\u001b[0m\u001b[1;32m    142\u001b[0m         Y = check_array(Y, accept_sparse=accept_sparse, dtype=dtype,\n\u001b[1;32m    143\u001b[0m                         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    554\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rawHX0VSHtAA",
        "colab_type": "code",
        "outputId": "254ab315-7211-4fb3-bcd5-917bd568460e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def make_similarity_df(base_vect, verbs_for_check_dict, model):\n",
        "  '''\n",
        "  Считает косинусное расстояние с каким-либо подающимся на вход сидовым глаголом глаголов из словаря, полученного с помощью \n",
        "  функции make_group. Возвращает словарь с ключами 'groups', 'base_verb', 'verb' и 'verbs_similarity', \n",
        "  которые потом будут колонками таблицы - датафрейма.\n",
        "  '''\n",
        "\n",
        "  df_dict = Counter()\n",
        "  df_dict['groups'] = []\n",
        "  df_dict['base_verb'] = []\n",
        "  df_dict['verb'] = []\n",
        "  df_dict['verbs_similarity'] = []\n",
        "\n",
        "  #my_base_verb = base_verb + '_V'\n",
        "  for verb in verbs_for_check_dict.keys():\n",
        "    verb_for_check = verb + '_V'\n",
        "    try:\n",
        "      verbs_similarity = model.similarity(base_vect, verb_for_check)\n",
        "      df_dict['groups'].append(str(verbs_for_check_dict[verb]))\n",
        "      df_dict['base_verb'].append(base_verb)\n",
        "      df_dict['verb'].append(verb)\n",
        "      df_dict['verbs_similarity'].append(verbs_similarity)\n",
        "    except KeyError as e:\n",
        "      pass\n",
        "      #print(e)\n",
        "  return df_dict\n",
        "\n",
        "verbs_for_df = make_similarity_df(opinion_embedding, groups_total_dict, rv_model)\n",
        "print('done')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBEDU194HtCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "frames_df = pd.DataFrame(verbs_for_df, columns = verbs_for_df.keys()) # тут делается датафрейм"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCwwlsdGHtFG",
        "colab_type": "code",
        "outputId": "0e0392f5-1302-4368-e570-535a55b06b36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "frames_df"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>groups</th>\n",
              "      <th>base_verb</th>\n",
              "      <th>verb</th>\n",
              "      <th>verbs_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [groups, base_verb, verb, verbs_similarity]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XdwIenPHtHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVcLWwG9BB3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}